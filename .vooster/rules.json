{
  "rules": [
    {
      "type": "prd",
      "content": "# ğŸ“˜ ì œí’ˆ ìš”êµ¬ì‚¬í•­ ë¬¸ì„œ (PRD)\n\n## 1. ê°œìš”\n\n- **ì œí’ˆ ì´ë¦„:** ReBridge\n    \n- **ì‘ì„± ì¼ì:** 2025-07-12 (rev. MVP-02)\n    \n- **ë¬¸ì„œ ëª©ì :** ì •ì‹ ì¥ì• ì¸ ë§ì¶¤ êµ¬ì§ ì •ë³´ í†µí•© í”Œë«í¼ì˜ **MVP** ê¸°ëŠ¥â€§ê¸°ìˆ  ìš”êµ¬ì‚¬í•­ì„ ì •ì˜í•œë‹¤. MVPëŠ” â€œêµ¬ì¸ ì •ë³´ ìˆ˜ì§‘Â·ì œê³µâ€ì— ì§‘ì¤‘í•´ **4ì£¼ ë‚´ ì‹¤ì‚¬ìš©** ê°€ëŠ¥í•œ ìµœì†Œ ì œí’ˆì„ ëª©í‘œë¡œ í•œë‹¤.\n    \n\n---\n\n## 2. ì œí’ˆ ëª©í‘œ (MVP ê´€ì )\n\n1. **ì±„ìš© ì •ë³´ ì ‘ê·¼ì„± ê·¹ëŒ€í™”** â€“ ì£¼ìš” 4ê°œ ì±„ë„ì˜ ê³µê³ ë¥¼ ë§¤ì¼ ìë™ ìˆ˜ì§‘â€§ì •ê·œí™”â€§ê²€ìƒ‰ ì œê³µ.\n    \n2. **ê°œì¸í™” ê¸°ë°˜ ì €ì¥Â·ì•Œë¦¼** â€“ ì‚¬ìš©ìëŠ” ê´€ì‹¬ ê³µê³ ë¥¼ ì €ì¥í•˜ê³ , ìƒˆÂ·ë§ˆê° ê³µê³  ì•Œë¦¼ì„ ìˆ˜ì‹ í•œë‹¤.\n    \n3. **ë‹¨ìˆœ ìŠ¤íƒìœ¼ë¡œ ë¹ ë¥¸ ì¶œì‹œ** â€“ Next.js 14 + PostgreSQL + Redis 3ì¢…ìœ¼ë¡œ MVPë¥¼ êµ¬ì¶•, ì¶”í›„ AI ë§¤ì¹­Â·ì›Œí¬í”Œë¡œìš° ë“± í™•ì¥ì´ ê°€ëŠ¥í•˜ë„ë¡ ëª¨ë“ˆí˜• êµ¬ì¡°ë¥¼ í™•ë³´í•œë‹¤.\n    \n\n---\n\n## 3. ì£¼ìš” ê¸°ëŠ¥ (MVP ë²”ìœ„)\n\n|ë²ˆí˜¸|ê¸°ëŠ¥ëª…|ì„¤ëª…|\n|---|---|---|\n|3-1|**í†µí•© ì±„ìš© í”¼ë“œ**|ì›Œí¬íˆ¬ê²Œë”Â·ê³ ìš©24Â·ì‚¬ëŒì¸Â·ì¡ì½”ë¦¬ì•„ ê³µê³ ë¥¼ ìµœì‹ ìˆœÂ·í•„í„°ë³„ ë¦¬ìŠ¤íŠ¸/ìƒì„¸ë¡œ ì œê³µ|\n|3-2|**ê°„ë‹¨ ì‚¬ìš©ì í”„ë¡œí•„**|ì´ë©”ì¼Â·ë¹„ë°€ë²ˆí˜¸Â·ì¥ì•  ë“±ë¡ ì—¬ë¶€ë§Œ ë°›ëŠ” ê²½ëŸ‰ í”„ë¡œí•„, Saved JobsÂ·ì•Œë¦¼ ì„¤ì • ì €ì¥|\n|3-3|**ê¸°ë³¸ ì•Œë¦¼**|ì €ì¥í•œ ê³µê³  ìƒíƒœ ë³€í™”(ë§ˆê°â€§ìˆ˜ì •) ë° ì‹ ê·œ ì í•© ê³µê³  ë°œìƒ ì‹œ ì´ë©”ì¼Â·í‘¸ì‹œ ì „ì†¡|\n\n> **Phase 2 ì´í›„** â€“ AI ë§¤ì¹­, ì‹¬ë¦¬ ì²´í¬-ì¸, ìƒë‹´ ì˜ˆì•½, ì»¤ë®¤ë‹ˆí‹° ë“± ê³ ë„í™” ê¸°ëŠ¥ì€ ì°¨ê¸° ë‹¨ê³„ì—ì„œ ì¶”ê°€í•œë‹¤.\n\n---\n\n## 4. ì‚¬ìš©ì í”Œë¡œìš° (MVP)\n\n```mermaid\nflowchart TD\n    A(íšŒì›ê°€ì…/ë¡œê·¸ì¸) --> B(í”„ë¡œí•„ ê¸°ë³¸ ì •ë³´ ì…ë ¥)\n    B --> C(í†µí•© ì±„ìš© í”¼ë“œ ì¡°íšŒ)\n    C -->|ê´€ì‹¬ ê³µê³  ì €ì¥| D(ë‚´ ì €ì¥ ê³µê³  ëª©ë¡)\n    C -->|ê³µê³  ìƒì„¸ ì—´ëŒ| E(ê³µê³  ìƒì„¸)\n    D --> F(ê³µê³  ë§ˆê°Â·ìˆ˜ì • ì‹œ ì•Œë¦¼ ìˆ˜ì‹ )\n```\n\n---\n\n## 5. ê¸°ìˆ  ìš”êµ¬ì‚¬í•­ (MVP)\n\n### 5.1 í”„ë¡œì íŠ¸ êµ¬ì¡° & ì´ˆê¸° ì„¤ì •\n\n```bash\nrebridge/\nâ”œâ”€â”€ apps/\nâ”‚   â”œâ”€â”€ web/                 # Next.js 14 App Router (SSR + API Routes)\nâ”‚   â””â”€â”€ crawler/             # ë…ë¦½ í¬ë¡¤ëŸ¬ ì„œë¹„ìŠ¤ (Node + Puppeteer)\nâ”œâ”€â”€ packages/\nâ”‚   â”œâ”€â”€ database/            # Prisma ìŠ¤í‚¤ë§ˆ ë° í´ë¼ì´ì–¸íŠ¸\nâ”‚   â”œâ”€â”€ shared/              # ê³µìš© íƒ€ì…Â·ìœ í‹¸\nâ”‚   â””â”€â”€ crawler-adapters/    # ì‚¬ì´íŠ¸ë³„ í¬ë¡¤ëŸ¬ ë¡œì§\nâ””â”€â”€ docker-compose.yml       # ë¡œì»¬ ê°œë°œìš© (PostgreSQLÂ·Redis)\n```\n\n- **ëª¨ë…¸ë ˆí¬**(pnpm workspaces)ë¡œ ì½”ë“œÂ·íƒ€ì… ê³µìœ .\n    \n- **CI/CD:** GitHub Actions â†’ Vercel(ì›¹/API) / Upstash Redis / Neon PostgreSQL.\n    \n\n---\n\n### 5.2 ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   Next.js    â”‚  GraphQL â”‚  API Layer     â”‚  Prisma ORM\nâ”‚ (Web+API)    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  (App Router)  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º PostgreSQL (Neon)\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n        â–²                           â”‚\n        â”‚                           â–¼\n        â”‚  WebSocket / REST   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º   Redis      â”‚\n                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ (TTL ìºì‹œ Â· Job Queue)\n                                    â”‚\n                                    â–¼\n                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n                         â”‚  Crawler Manager     â”‚\n                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n---\n\n### 5.3 í¬ë¡¤ë§ ì„œë¸Œì‹œìŠ¤í…œ\n\n```typescript\n// packages/crawler-adapters/src/base.ts\nexport interface CrawlerAdapter {\n  source: 'workTogether' | 'work24' | 'saramin' | 'jobkorea';\n  crawl(page?: number): Promise<RawJobData[]>;\n  parseJobDetail(id: string): Promise<JobDetail>;\n  normalizeData(raw: RawJobData): NormalizedJob;\n}\n```\n\n```text\ní¬ë¡¤ëŸ¬ ë§¤ë‹ˆì €\nâ”œâ”€ ìŠ¤ì¼€ì¤„ëŸ¬ (node-cron, ë§¤ 6 h)\nâ”œâ”€ ì›Œì»¤ í’€ (Puppeteer, concurrency=4)\nâ”‚  â”œâ”€ WorkTogetherAdapter   { type:'static',  delay:3 s }\nâ”‚  â”œâ”€ Work24Adapter         { type:'dynamic', delay:5 s }\nâ”‚  â”œâ”€ SaraminAdapter        { type:'api',     delay:2 s }\nâ”‚  â””â”€ JobKoreaAdapter       { type:'dynamic', delay:4 s }\nâ”œâ”€ íŒŒì„œ/ì •ê·œí™”                (Cheerio + Zod)\nâ””â”€ DB ì €ì¥ê¸°                  (Prisma Tx)\n```\n\n- **ë ˆì´íŠ¸ ë¦¬ë°‹:** ìš”ì²­ ê°„ê²© 2-5 ì´ˆ, IP Block ëŒ€ë¹„.\n    \n- **ì¬ì‹œë„:** ìµœëŒ€ 3íšŒ + ì§€ìˆ˜ Backoff(1â†’2â†’4 s).\n    \n- **ì¤‘ë³µ ì²´í¬:** `(source, external_id)` ê³ ìœ  í‚¤.\n    \n- **robots.txt ì¤€ìˆ˜ ë° User-Agent ì‹ë³„**ìœ¼ë¡œ ë²•ì Â·ìœ¤ë¦¬ì  ì´ìŠˆ ì˜ˆë°©.\n    \n\n---\n\n### 5.4 ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ (í•µì‹¬ 4 í…Œì´ë¸”)\n\n```sql\nCREATE TABLE users (\n    id                       UUID PRIMARY KEY,\n    email                    VARCHAR(255) UNIQUE NOT NULL,\n    password_hash            VARCHAR(255)        NOT NULL,\n    is_registered_disability BOOLEAN DEFAULT FALSE,\n    created_at               TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE jobs (\n    id                      UUID PRIMARY KEY,\n    source                  VARCHAR(50) NOT NULL,\n    external_id             VARCHAR(255) NOT NULL,\n    title                   TEXT NOT NULL,\n    company                 VARCHAR(255),\n    location_json           JSONB,\n    salary_range            JSONB,\n    employment_type         VARCHAR(50),\n    description             TEXT,\n    is_disability_friendly  BOOLEAN DEFAULT FALSE,\n    crawled_at              TIMESTAMP,\n    expires_at              TIMESTAMP,\n    raw_data                JSONB,\n    search_vector           TSVECTOR,\n    UNIQUE (source, external_id)\n);\n\nCREATE INDEX jobs_crawled_idx ON jobs (crawled_at DESC);\nCREATE INDEX jobs_company_title_idx ON jobs (company, title);\nCREATE INDEX jobs_search_idx ON jobs USING GIN(search_vector);\n\nCREATE TABLE user_saved_jobs (\n    user_id UUID REFERENCES users(id),\n    job_id  UUID REFERENCES jobs(id),\n    saved_at TIMESTAMP DEFAULT NOW(),\n    PRIMARY KEY(user_id, job_id)\n);\n\nCREATE TABLE crawl_logs (\n    id UUID PRIMARY KEY,\n    source VARCHAR(50),\n    status VARCHAR(20),\n    jobs_found INT,\n    jobs_new INT,\n    jobs_updated INT,\n    error_message TEXT,\n    started_at TIMESTAMP,\n    completed_at TIMESTAMP\n);\n```\n\n#### âœ ì „ë¬¸ ê²€ìƒ‰ ìµœì í™”\n\n```sql\nCREATE TRIGGER jobs_search_vector_update\nBEFORE INSERT OR UPDATE ON jobs\nFOR EACH ROW EXECUTE FUNCTION\ntsvector_update_trigger(search_vector,\n                        'pg_catalog.korean',\n                        title, company, description);\n```\n\n---\n\n### 5.5 API & í™”ë©´ êµ¬í˜„ (Next.js 14)\n\n```typescript\n// app/jobs/page.tsx  â”€ ì„œë²„ ì»´í¬ë„ŒíŠ¸ (SEO)\nexport default async function JobsPage({\n  searchParams\n}: { searchParams: { page?: string; q?: string } }) {\n  const page = Number(searchParams.page ?? 1);\n  const q = searchParams.q;\n\n  const jobs = await prisma.job.findMany({\n    where: q ? {\n      OR: [\n        { title:   { contains: q, mode: 'insensitive' } },\n        { company: { contains: q, mode: 'insensitive' } }\n      ]\n    } : undefined,\n    orderBy: { crawledAt: 'desc' },\n    take: 20,\n    skip: (page - 1) * 20\n  });\n\n  return <JobList jobs={jobs} />;\n}\n```\n\n- **App Router (Server Components)** ë¡œ SEO, ìºì‹±(Tags) ìµœì í™”.\n    \n- **NextAuth.js** (Credentials + Kakao OAuth) ë¡œ ê¹”ë”í•œ ì¸ì¦.\n    \n\n---\n\n### 5.6 ì•Œë¦¼ & ìºì‹±\n\n```typescript\n// Redis Pub/Sub Worker (BullMQ)\nconst notificationWorker = new Worker('notification', async job => {\n  const { userId, type, jobId } = job.data;\n  const user = await prisma.user.findUnique({ where: { id: userId } });\n\n  if (type === 'jobExpiring') {\n    await sendEmail({\n      to: user.email,\n      subject: 'ì €ì¥í•œ ê³µê³ ê°€ ê³§ ë§ˆê°ë©ë‹ˆë‹¤',\n      html: /* â€¦ */\n    });\n  }\n});\n```\n\n- **ìºì‹±** â€“ `jobs:latest` í‚¤ì— ìµœê·¼ 100ê±´ JSON ì €ì¥, TTL 1 h\n    \n- **ì§€ì†ì„±** â€“ Upstash Redis Durable Streamsë¡œ ì•Œë¦¼ ì´ì¤‘í™”.\n    \n\n---\n\n### 5.7 ì„±ëŠ¥ & ëª¨ë‹ˆí„°ë§\n\n```typescript\n// jobs API with cache\nexport async function GET() {\n  const cached = await redis.get('jobs:latest');\n  if (cached) return Response.json(JSON.parse(cached));\n\n  const jobs = await prisma.job.findMany({\n    orderBy: { crawledAt: 'desc' },\n    take: 100\n  });\n  await redis.setex('jobs:latest', 3600, JSON.stringify(jobs));\n  return Response.json(jobs);\n}\n```\n\n```typescript\n// admin/crawl-status\nconst logs = await prisma.crawlLog.findMany({\n  orderBy: { startedAt: 'desc' },\n  take: 50\n});\nconst successRate = logs.filter(l => l.status === 'success').length / logs.length;\n```\n\n- **ëª¨ë‹ˆí„°ë§** â€“ Grafana Cloud ëŒ€ì‹œë³´ë“œ + Vercel Analytics.\n    \n- **Alert** â€“ crawl ì‹¤íŒ¨ìœ¨ > 20 % or í‰ê·  ì‹œê°„ > 15 min ì‹œ Slackâ€§ë©”ì¼ ì•Œë¦¼.\n    \n\n---\n\n### 5.8 ê°œë°œ ìš°ì„ ìˆœìœ„ (4 ì£¼ ê³„íš)\n\n|ì£¼ì°¨|í•µì‹¬ ì‚°ì¶œë¬¼|\n|---|---|\n|**Week 1**|ëª¨ë…¸ë ˆí¬ ì„¸íŒ…, Prisma ìŠ¤í‚¤ë§ˆ, ê¸°ë³¸ ì¸ì¦(NextAuth)|\n|**Week 2**|WorkTogetherÂ·Saramin í¬ë¡¤ëŸ¬, ë°ì´í„° ì •ê·œí™” & ì €ì¥ ë¡œì§|\n|**Week 3**|ì±„ìš© í”¼ë“œ UI/ê²€ìƒ‰/ì €ì¥, Redis ìºì‹œ|\n|**Week 4**|ê³ ìš©24Â·ì¡ì½”ë¦¬ì•„ í¬ë¡¤ëŸ¬, ì•Œë¦¼ ì‹œìŠ¤í…œ, ë°°í¬ & ëª¨ë‹ˆí„°ë§|\n\n> **ì¼ì •ì€ ê°€ì´ë“œë¼ì¸**ì´ë©°, ìº˜ë¦°ë” êµ¬ì²´ ë‚ ì§œëŠ” ë³„ë„ ìŠ¤í”„ë¦°íŠ¸ ë³´ë“œì—ì„œ ê´€ë¦¬í•œë‹¤.\n\n---\n\n## 6. ê¸°íƒ€ / ë¹„ê³ \n\n- **ë³´ì•ˆ:** bcrypt(12) í•´ì‹œ, JWT + Refresh Token, TLS 1.3.\n    \n- **ë°ì´í„° ìœ¤ë¦¬:** robots.txt ì¤€ìˆ˜, ì›ë³¸ ì‚¬ì´íŠ¸ ì•½ê´€ ë²”ìœ„ ë‚´ ë°ì´í„° ì‚¬ìš©, â€œRight to Be Forgottenâ€ ì§€ì›.\n    \n- **ì ‘ê·¼ì„±:** WCAG 2.1 AA, ë‹¤í¬ëª¨ë“œÂ·í‚¤ë³´ë“œ ë‚´ë¹„ê²Œì´ì…˜Â·ìŠ¤í¬ë¦°ë¦¬ë” ë¼ë²¨ ì™„ë¹„.\n    \n- **í–¥í›„ í™•ì¥:** AI ì§ë¬´ ë§¤ì¹­Â·ì›Œí¬í”Œë¡œìš° ë³´ë“œ ë“±ì€ ë…ë¦½ **service package** ë¡œ ì¶”ê°€, API Gatewayì—ì„œ GraphQL Federationìœ¼ë¡œ í†µí•©í•  ìˆ˜ ìˆë„ë¡ ë„ë©”ì¸ ê²½ê³„ ìœ ì§€.\n    \n\n**ë¬¸ì„œ ì¢…ë£Œ.**",
      "writedAt": "2025-07-13T08:44:41.977Z"
    },
    {
      "type": "architecture",
      "content": "# ğŸ“ ê¸°ìˆ  ìš”êµ¬ì‚¬í•­ ë¬¸ì„œ (TRD)\n\n## 1. ë¬¸ì„œ ê°œìš”\n\n- **ì œí’ˆëª…:** ReBridge\n- **ì‘ì„±ì¼:** 2025-07-12\n- **ë²„ì „:** 1.0 (MVP)\n- **ëª©ì :** PRDì— ì •ì˜ëœ MVP ê¸°ëŠ¥ì„ êµ¬í˜„í•˜ê¸° ìœ„í•œ ìƒì„¸ ê¸°ìˆ  ëª…ì„¸ ë° êµ¬í˜„ ê°€ì´ë“œ\n\n---\n\n## 2. ê¸°ìˆ  ìŠ¤íƒ ìƒì„¸\n\n### 2.1 í•µì‹¬ ê¸°ìˆ  ìŠ¤íƒ\n\n|ê³„ì¸µ|ê¸°ìˆ |ë²„ì „|ì„ íƒ ì´ìœ |\n|---|---|---|---|\n|**Frontend**|Next.js|14.2.x|App Router, RSC, SEO ìµœì í™”|\n|**Backend**|Next.js API Routes|14.2.x|ë‹¨ì¼ ì½”ë“œë² ì´ìŠ¤, Edge Runtime ì§€ì›|\n|**Database**|PostgreSQL (Neon)|16|Serverless, ìë™ ìŠ¤ì¼€ì¼ë§, í•œêµ­ì–´ ì „ë¬¸ê²€ìƒ‰|\n|**Cache/Queue**|Upstash Redis|Latest|Serverless Redis, ë‚®ì€ ë ˆì´í„´ì‹œ|\n|**ORM**|Prisma|5.x|íƒ€ì… ì•ˆì „ì„±, ë§ˆì´ê·¸ë ˆì´ì…˜ ê´€ë¦¬|\n|**í¬ë¡¤ë§**|Puppeteer/Playwright|Latest|ë™ì  ì‚¬ì´íŠ¸ ì²˜ë¦¬, ì•ˆì •ì„±|\n|**ì¸ì¦**|NextAuth.js|5.x|ë‹¤ì–‘í•œ Provider ì§€ì›|\n|**ëª¨ë…¸ë ˆí¬**|pnpm + Turborepo|Latest|ë¹ ë¥¸ ë¹Œë“œ, íš¨ìœ¨ì  ìºì‹±|\n\n### 2.2 ê°œë°œ ë„êµ¬\n\n```json\n{\n  \"typescript\": \"^5.3\",\n  \"eslint\": \"^8.57\",\n  \"prettier\": \"^3.2\",\n  \"vitest\": \"^1.2\",\n  \"playwright\": \"^1.41\"\n}\n```\n\n---\n\n## 3. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ìƒì„¸\n\n### 3.1 ì „ì²´ ì•„í‚¤í…ì²˜\n\n```mermaid\ngraph TB\n    subgraph \"Client Layer\"\n        A[Next.js SSR/CSR]\n        B[PWA Service Worker]\n    end\n    \n    subgraph \"API Layer\"\n        C[Next.js API Routes]\n        D[GraphQL Yoga]\n        E[NextAuth.js]\n    end\n    \n    subgraph \"Service Layer\"\n        F[Job Service]\n        G[User Service]\n        H[Notification Service]\n        I[Crawler Manager]\n    end\n    \n    subgraph \"Data Layer\"\n        J[(PostgreSQL)]\n        K[(Redis)]\n        L[Prisma ORM]\n    end\n    \n    subgraph \"External\"\n        M[WorkTogether]\n        N[ê³ ìš©24]\n        O[ì‚¬ëŒì¸]\n        P[ì¡ì½”ë¦¬ì•„]\n    end\n    \n    A --> C\n    B --> C\n    C --> D\n    D --> F\n    D --> G\n    D --> H\n    F --> L\n    G --> L\n    H --> K\n    I --> L\n    I --> M\n    I --> N\n    I --> O\n    I --> P\n    L --> J\n    H --> K\n```\n\n### 3.2 ë°ì´í„° íë¦„\n\n```typescript\n// í¬ë¡¤ë§ â†’ ì €ì¥ â†’ ìºì‹± â†’ ì œê³µ\ninterface DataFlow {\n  1. \"í¬ë¡¤ëŸ¬ê°€ ì™¸ë¶€ ì‚¬ì´íŠ¸ì—ì„œ ë°ì´í„° ìˆ˜ì§‘\"\n  2. \"ì–´ëŒ‘í„°ê°€ ë°ì´í„° ì •ê·œí™”\"\n  3. \"Prismaë¡œ PostgreSQL ì €ì¥\"\n  4. \"Redisì— ìµœì‹  ë°ì´í„° ìºì‹±\"\n  5. \"APIê°€ ìºì‹œ ìš°ì„  ì¡°íšŒ í›„ ì‘ë‹µ\"\n}\n```\n\n---\n\n## 4. API ì„¤ê³„\n\n### 4.1 GraphQL ìŠ¤í‚¤ë§ˆ\n\n```graphql\ntype Query {\n  # ì±„ìš© ê³µê³  ì¡°íšŒ\n  jobs(\n    page: Int = 1\n    limit: Int = 20\n    search: String\n    filters: JobFilterInput\n  ): JobConnection!\n  \n  # ë‹¨ì¼ ê³µê³  ìƒì„¸\n  job(id: ID!): Job\n  \n  # ë‚´ ì €ì¥ ê³µê³ \n  savedJobs(page: Int = 1, limit: Int = 20): JobConnection!\n  \n  # í˜„ì¬ ì‚¬ìš©ì ì •ë³´\n  me: User\n}\n\ntype Mutation {\n  # ì¸ì¦\n  signUp(input: SignUpInput!): AuthPayload!\n  signIn(input: SignInInput!): AuthPayload!\n  signOut: Boolean!\n  \n  # ê³µê³  ì €ì¥/ì‚­ì œ\n  saveJob(jobId: ID!): Job!\n  unsaveJob(jobId: ID!): Boolean!\n  \n  # í”„ë¡œí•„ ì—…ë°ì´íŠ¸\n  updateProfile(input: UpdateProfileInput!): User!\n}\n\ntype Subscription {\n  # ìƒˆ ê³µê³  ì•Œë¦¼\n  newJobs(filters: JobFilterInput): Job!\n}\n\n# íƒ€ì… ì •ì˜\ntype Job {\n  id: ID!\n  source: JobSource!\n  externalId: String!\n  title: String!\n  company: String\n  location: Location\n  salaryRange: SalaryRange\n  employmentType: String\n  description: String!\n  isDisabilityFriendly: Boolean!\n  crawledAt: DateTime!\n  expiresAt: DateTime\n  isSaved: Boolean!\n}\n\ntype JobConnection {\n  edges: [JobEdge!]!\n  pageInfo: PageInfo!\n  totalCount: Int!\n}\n\ninput JobFilterInput {\n  sources: [JobSource!]\n  isDisabilityFriendly: Boolean\n  employmentTypes: [String!]\n  locationIds: [String!]\n}\n\nenum JobSource {\n  WORK_TOGETHER\n  WORK24\n  SARAMIN\n  JOBKOREA\n}\n```\n\n### 4.2 REST API ì—”ë“œí¬ì¸íŠ¸\n\n```typescript\n// Health Check\nGET /api/health\n\n// í¬ë¡¤ëŸ¬ Webhook\nPOST /api/crawler/trigger\n{\n  \"source\": \"workTogether\",\n  \"secret\": \"CRAWLER_SECRET\"\n}\n\n// íŒŒì¼ ì—…ë¡œë“œ (ì´ë ¥ì„œ ë“±)\nPOST /api/upload\nContent-Type: multipart/form-data\n```\n\n---\n\n## 5. ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„\n\n### 5.1 Prisma ìŠ¤í‚¤ë§ˆ\n\n```prisma\n// prisma/schema.prisma\ngenerator client {\n  provider = \"prisma-client-js\"\n  previewFeatures = [\"fullTextSearch\", \"postgresqlExtensions\"]\n}\n\ndatasource db {\n  provider = \"postgresql\"\n  url = env(\"DATABASE_URL\")\n  extensions = [pgcrypto, pg_trgm]\n}\n\nmodel User {\n  id                      String    @id @default(dbgenerated(\"gen_random_uuid()\"))\n  email                   String    @unique\n  passwordHash            String    @map(\"password_hash\")\n  isRegisteredDisability  Boolean   @default(false) @map(\"is_registered_disability\")\n  createdAt               DateTime  @default(now()) @map(\"created_at\")\n  updatedAt               DateTime  @updatedAt @map(\"updated_at\")\n  \n  profile                 Profile?\n  savedJobs              SavedJob[]\n  notifications          Notification[]\n  \n  @@map(\"users\")\n}\n\nmodel Profile {\n  userId          String   @id @map(\"user_id\")\n  name            String?\n  phoneNumber     String?  @map(\"phone_number\")\n  preferredAreas  Json?    @map(\"preferred_areas\")\n  emailAlerts     Boolean  @default(true) @map(\"email_alerts\")\n  pushAlerts      Boolean  @default(false) @map(\"push_alerts\")\n  \n  user            User     @relation(fields: [userId], references: [id], onDelete: Cascade)\n  \n  @@map(\"profiles\")\n}\n\nmodel Job {\n  id                    String    @id @default(dbgenerated(\"gen_random_uuid()\"))\n  source               String\n  externalId           String    @map(\"external_id\")\n  title                String\n  company              String?\n  locationJson         Json?     @map(\"location_json\")\n  salaryRange          Json?     @map(\"salary_range\")\n  employmentType       String?   @map(\"employment_type\")\n  description          String    @db.Text\n  isDisabilityFriendly Boolean   @default(false) @map(\"is_disability_friendly\")\n  crawledAt            DateTime  @map(\"crawled_at\")\n  expiresAt            DateTime? @map(\"expires_at\")\n  rawData              Json      @map(\"raw_data\")\n  \n  savedBy              SavedJob[]\n  \n  @@unique([source, externalId])\n  @@index([crawledAt(sort: Desc)])\n  @@index([company, title])\n  @@map(\"jobs\")\n}\n\nmodel SavedJob {\n  userId    String   @map(\"user_id\")\n  jobId     String   @map(\"job_id\")\n  savedAt   DateTime @default(now()) @map(\"saved_at\")\n  \n  user      User     @relation(fields: [userId], references: [id], onDelete: Cascade)\n  job       Job      @relation(fields: [jobId], references: [id], onDelete: Cascade)\n  \n  @@id([userId, jobId])\n  @@map(\"user_saved_jobs\")\n}\n\nmodel CrawlLog {\n  id            String    @id @default(dbgenerated(\"gen_random_uuid()\"))\n  source        String\n  status        String\n  jobsFound     Int       @map(\"jobs_found\")\n  jobsNew       Int       @map(\"jobs_new\")\n  jobsUpdated   Int       @map(\"jobs_updated\")\n  errorMessage  String?   @map(\"error_message\")\n  startedAt     DateTime  @map(\"started_at\")\n  completedAt   DateTime? @map(\"completed_at\")\n  \n  @@index([startedAt(sort: Desc)])\n  @@map(\"crawl_logs\")\n}\n\nmodel Notification {\n  id        String   @id @default(dbgenerated(\"gen_random_uuid()\"))\n  userId    String   @map(\"user_id\")\n  type      String\n  payload   Json\n  isRead    Boolean  @default(false) @map(\"is_read\")\n  createdAt DateTime @default(now()) @map(\"created_at\")\n  \n  user      User     @relation(fields: [userId], references: [id], onDelete: Cascade)\n  \n  @@index([userId, isRead])\n  @@map(\"notifications\")\n}\n```\n\n### 5.2 ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ\n\n```bash\n# ì´ˆê¸° ë§ˆì´ê·¸ë ˆì´ì…˜\npnpm prisma migrate dev --name init\n\n# ì „ë¬¸ê²€ìƒ‰ ì¸ë±ìŠ¤ ì¶”ê°€\npnpm prisma migrate dev --name add_fulltext_search\n\n# í”„ë¡œë•ì…˜ ë°°í¬\npnpm prisma migrate deploy\n```\n\n---\n\n## 6. í¬ë¡¤ëŸ¬ êµ¬í˜„ ìƒì„¸\n\n### 6.1 í¬ë¡¤ëŸ¬ ì¸í„°í˜ì´ìŠ¤\n\n```typescript\n// packages/crawler-adapters/src/types.ts\nexport interface RawJobData {\n  id: string;\n  title: string;\n  company?: string;\n  location?: string;\n  salary?: string;\n  type?: string;\n  description?: string;\n  postedAt?: string;\n  deadline?: string;\n  url: string;\n  raw: Record<string, unknown>;\n}\n\nexport interface NormalizedJob {\n  externalId: string;\n  title: string;\n  company: string | null;\n  locationJson: {\n    city?: string;\n    district?: string;\n    address?: string;\n  } | null;\n  salaryRange: {\n    min?: number;\n    max?: number;\n    type?: 'monthly' | 'yearly';\n  } | null;\n  employmentType: string | null;\n  description: string;\n  isDisabilityFriendly: boolean;\n  expiresAt: Date | null;\n  rawData: Record<string, unknown>;\n}\n\nexport abstract class BaseCrawler implements CrawlerAdapter {\n  abstract source: JobSource;\n  protected page: Page | null = null;\n  \n  abstract crawl(pageNum?: number): Promise<RawJobData[]>;\n  abstract parseJobDetail(id: string): Promise<JobDetail>;\n  abstract normalizeData(raw: RawJobData): NormalizedJob;\n  \n  protected async initBrowser(): Promise<void> {\n    const browser = await chromium.launch({\n      headless: true,\n      args: ['--no-sandbox', '--disable-setuid-sandbox']\n    });\n    this.page = await browser.newPage();\n    await this.page.setViewportSize({ width: 1920, height: 1080 });\n  }\n  \n  protected async delay(ms: number): Promise<void> {\n    await new Promise(resolve => setTimeout(resolve, ms));\n  }\n}\n```\n\n### 6.2 í¬ë¡¤ëŸ¬ ìŠ¤ì¼€ì¤„ë§\n\n```typescript\n// apps/crawler/src/scheduler.ts\nimport { CronJob } from 'cron';\nimport { Queue } from 'bullmq';\n\nconst crawlQueue = new Queue('crawl-jobs', {\n  connection: redis\n});\n\n// 6ì‹œê°„ë§ˆë‹¤ ì‹¤í–‰\nconst job = new CronJob('0 */6 * * *', async () => {\n  const sources = ['workTogether', 'work24', 'saramin', 'jobkorea'];\n  \n  for (const source of sources) {\n    await crawlQueue.add('crawl', { \n      source,\n      timestamp: new Date().toISOString()\n    }, {\n      attempts: 3,\n      backoff: {\n        type: 'exponential',\n        delay: 2000\n      }\n    });\n  }\n});\n\njob.start();\n```\n\n---\n\n## 7. ë³´ì•ˆ ìš”êµ¬ì‚¬í•­\n\n### 7.1 ì¸ì¦ ë° ê¶Œí•œ\n\n```typescript\n// lib/auth.ts\nexport const authOptions: NextAuthOptions = {\n  providers: [\n    CredentialsProvider({\n      credentials: {\n        email: { type: \"email\" },\n        password: { type: \"password\" }\n      },\n      async authorize(credentials) {\n        const user = await prisma.user.findUnique({\n          where: { email: credentials.email }\n        });\n        \n        if (!user) return null;\n        \n        const isValid = await bcrypt.compare(\n          credentials.password,\n          user.passwordHash\n        );\n        \n        if (!isValid) return null;\n        \n        return {\n          id: user.id,\n          email: user.email\n        };\n      }\n    }),\n    KakaoProvider({\n      clientId: process.env.KAKAO_CLIENT_ID!,\n      clientSecret: process.env.KAKAO_CLIENT_SECRET!\n    })\n  ],\n  session: {\n    strategy: 'jwt',\n    maxAge: 30 * 24 * 60 * 60 // 30ì¼\n  },\n  jwt: {\n    secret: process.env.JWT_SECRET!\n  }\n};\n```\n\n### 7.2 ë³´ì•ˆ ë¯¸ë“¤ì›¨ì–´\n\n```typescript\n// middleware.ts\nexport const config = {\n  matcher: ['/api/:path*', '/profile/:path*']\n};\n\nexport function middleware(request: NextRequest) {\n  // CSRF í† í° ê²€ì¦\n  const token = request.headers.get('x-csrf-token');\n  if (!token || !verifyCSRFToken(token)) {\n    return new Response('Invalid CSRF token', { status: 403 });\n  }\n  \n  // Rate Limiting\n  const ip = request.ip ?? 'unknown';\n  const identifier = `${ip}:${request.url}`;\n  \n  // API ë ˆì´íŠ¸ ë¦¬ë°‹: ë¶„ë‹¹ 60íšŒ\n  if (isRateLimited(identifier, 60, 60)) {\n    return new Response('Too Many Requests', { status: 429 });\n  }\n  \n  return NextResponse.next();\n}\n```\n\n---\n\n## 8. ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­\n\n### 8.1 ì„±ëŠ¥ ëª©í‘œ\n\n|ë©”íŠ¸ë¦­|ëª©í‘œê°’|ì¸¡ì • ë°©ë²•|\n|---|---|---|\n|**í˜ì´ì§€ ë¡œë“œ**|< 2ì´ˆ (LCP)|Lighthouse|\n|**API ì‘ë‹µ**|< 200ms (p95)|Grafana|\n|**í¬ë¡¤ë§ ì£¼ê¸°**|6ì‹œê°„|CronJob|\n|**DB ì¿¼ë¦¬**|< 50ms (p95)|Prisma Metrics|\n|**ë™ì‹œ ì‚¬ìš©ì**|1,000ëª…|K6 ë¶€í•˜í…ŒìŠ¤íŠ¸|\n\n### 8.2 ìµœì í™” ì „ëµ\n\n```typescript\n// ìºì‹± ì „ëµ\nconst cacheStrategy = {\n  jobs: {\n    list: 3600,      // 1ì‹œê°„\n    detail: 7200,    // 2ì‹œê°„\n    search: 1800     // 30ë¶„\n  },\n  user: {\n    profile: 300,    // 5ë¶„\n    savedJobs: 60    // 1ë¶„\n  }\n};\n\n// ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ìµœì í™”\nconst optimizedJobQuery = prisma.$queryRaw`\n  SELECT j.*, \n         EXISTS(SELECT 1 FROM user_saved_jobs WHERE job_id = j.id AND user_id = ${userId}) as is_saved\n  FROM jobs j\n  WHERE j.crawled_at > NOW() - INTERVAL '7 days'\n  ORDER BY j.crawled_at DESC\n  LIMIT 20 OFFSET ${offset}\n`;\n```\n\n---\n\n## 9. ë°°í¬ ë° ì¸í”„ë¼\n\n### 9.1 ë°°í¬ íŒŒì´í”„ë¼ì¸\n\n```yaml\n# .github/workflows/deploy.yml\nname: Deploy\non:\n  push:\n    branches: [main]\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: pnpm/action-setup@v2\n      - uses: actions/setup-node@v4\n        with:\n          node-version: '20'\n          cache: 'pnpm'\n      \n      - run: pnpm install --frozen-lockfile\n      - run: pnpm test\n      - run: pnpm build\n      \n      - name: Deploy to Vercel\n        run: vercel --prod\n        env:\n          VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN }}\n```\n\n### 9.2 í™˜ê²½ ë³€ìˆ˜\n\n```env\n# .env.production\nDATABASE_URL=\nREDIS_URL=\nNEXTAUTH_URL=\nNEXTAUTH_SECRET=\nJWT_SECRET=\nKAKAO_CLIENT_ID=\nKAKAO_CLIENT_SECRET=\nCRAWLER_SECRET=\nRESEND_API_KEY=\nSENTRY_DSN=\n```\n\n---\n\n## 10. ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…\n\n### 10.1 ë¡œê¹… ì „ëµ\n\n```typescript\n// lib/logger.ts\nimport pino from 'pino';\n\nexport const logger = pino({\n  level: process.env.LOG_LEVEL || 'info',\n  transport: {\n    target: 'pino-pretty',\n    options: {\n      colorize: true\n    }\n  }\n});\n\n// í¬ë¡¤ë§ ë¡œê·¸\nlogger.info({\n  type: 'crawl_completed',\n  source: 'workTogether',\n  jobsFound: 150,\n  jobsNew: 23,\n  duration: 45000\n});\n```\n\n### 10.2 ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ\n\n```typescript\n// ì£¼ìš” ë©”íŠ¸ë¦­\ninterface Metrics {\n  // í¬ë¡¤ë§\n  crawlSuccessRate: number;\n  avgCrawlDuration: number;\n  totalJobsCrawled: number;\n  \n  // API\n  apiRequestRate: number;\n  apiErrorRate: number;\n  apiResponseTime: number;\n  \n  // ì‚¬ìš©ì\n  activeUsers: number;\n  newSignups: number;\n  savedJobsCount: number;\n}\n```\n\n---\n\n## 11. í…ŒìŠ¤íŠ¸ ì „ëµ\n\n### 11.1 í…ŒìŠ¤íŠ¸ êµ¬ì¡°\n\n```typescript\n// ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ\ndescribe('JobNormalizer', () => {\n  it('should normalize salary range correctly', () => {\n    const raw = { salary: '300-400ë§Œì›' };\n    const normalized = normalizer.normalizeSalary(raw);\n    \n    expect(normalized).toEqual({\n      min: 3000000,\n      max: 4000000,\n      type: 'monthly'\n    });\n  });\n});\n\n// E2E í…ŒìŠ¤íŠ¸\ntest('user can save and view jobs', async ({ page }) => {\n  await page.goto('/jobs');\n  await page.click('[data-testid=\"job-save-button\"]');\n  await page.goto('/saved-jobs');\n  \n  await expect(page.locator('[data-testid=\"saved-job-item\"]')).toBeVisible();\n});\n```\n\n---\n\n## 12. ê¸°ìˆ ì  ìœ„í—˜ ë° ëŒ€ì‘\n\n|ìœ„í—˜ ìš”ì†Œ|ì˜í–¥ë„|ëŒ€ì‘ ë°©ì•ˆ|\n|---|---|---|\n|**í¬ë¡¤ë§ ì°¨ë‹¨**|ë†’ìŒ|User-Agent ë¡œí…Œì´ì…˜, í”„ë¡ì‹œ ì¤€ë¹„|\n|**ë°ì´í„° ì •ê·œí™” ì‹¤íŒ¨**|ì¤‘ê°„|ì›ë³¸ ë°ì´í„° ë³´ì¡´, ìˆ˜ë™ ê²€ìˆ˜|\n|**íŠ¸ë˜í”½ ê¸‰ì¦**|ì¤‘ê°„|Auto-scaling, CDN í™œìš©|\n|**ë³´ì•ˆ ì·¨ì•½ì **|ë†’ìŒ|ì •ê¸° ë³´ì•ˆ ê°ì‚¬, OWASP ì²´í¬|\n\n---\n\n## 13. ê°œë°œ ê·œì¹™\n\n### 13.1 ì½”ë“œ ìŠ¤íƒ€ì¼\n\n```typescript\n// ESLint ì„¤ì •\n{\n  \"extends\": [\"next/core-web-vitals\", \"prettier\"],\n  \"rules\": {\n    \"no-console\": [\"error\", { \"allow\": [\"warn\", \"error\"] }],\n    \"@typescript-eslint/explicit-function-return-type\": \"error\"\n  }\n}\n```\n\n### 13.2 ì»¤ë°‹ ê·œì¹™\n\n```bash\n# Conventional Commits\nfeat: ìƒˆë¡œìš´ ê¸°ëŠ¥\nfix: ë²„ê·¸ ìˆ˜ì •\ndocs: ë¬¸ì„œ ìˆ˜ì •\nstyle: ì½”ë“œ í¬ë§·íŒ…\nrefactor: ì½”ë“œ ë¦¬íŒ©í† ë§\ntest: í…ŒìŠ¤íŠ¸ ì¶”ê°€/ìˆ˜ì •\nchore: ë¹Œë“œ/ì„¤ì • ìˆ˜ì •\n```\n\n---\n",
      "writedAt": "2025-07-13T08:44:41.977Z"
    },
    {
      "type": "guideline",
      "content": "# Code Guideline for ReBridge\n\n## 1. Project Overview  \n- Monorepo (pnpm workspaces) with:  \n  - `apps/web` â€“ Next.js 14 App Router (SSR/Server Components) + API Routes + GraphQL  \n  - `apps/crawler` â€“ Node.js + Puppeteer crawler service (Cron + BullMQ)  \n  - `packages/database` â€“ Prisma schema & client singleton  \n  - `packages/shared` â€“ shared types & utils  \n  - `packages/crawler-adapters` â€“ site-specific crawler logic  \n- Data flow: Crawler â†’ Zod parsing â†’ Prisma â†’ Upstash Redis (TTL cache, BullMQ queues) â†’ Next.js API/GraphQL â†’ Frontend  \n- CI/CD: GitHub Actions â†’ Vercel (Web/API), Neon PostgreSQL, Upstash Redis  \n- Key patterns: Server Components for SEO/caching, cache-first queries, modular feature folders, strict error contracts  \n\n## 2. Core Principles  \n1. **Type Safety** â€“ All exported functions/components MUST declare explicit TypeScript types.  \n2. **Single Responsibility** â€“ Modules/functions â‰¤ 200 LOC and address one concern.  \n3. **Consistent Error Handling** â€“ Wrap all async logic in `try/catch` and return standardized `ApiError`.  \n4. **Resource Efficiency** â€“ Batch DB writes and cache reads; measure with query-count metrics.  \n5. **Modularity & Reuse** â€“ Shared utilities and types MUST reside in shared packages; no duplication.\n\n## 3. Language-Specific Guidelines\n\n### 3.1 TypeScript & Next.js  \n- File organization:  \n  - `apps/web/app/feature-name/` containing `page.tsx`, `route.ts`, `Component.tsx`  \n  - `components/` for UI atoms/molecules, `features/` for pages  \n- Imports:  \n  - Use absolute paths via `tsconfig.json` `baseUrl`/`paths`  \n  - Avoid `../../../`; max two relative levels  \n- Error handling:  \n  - API routes/GraphQL resolvers MUST throw/return `ApiError({ status, code, message })`  \n  - Use Next.js `error.js` boundaries for UI\n\n### 3.2 Prisma & Database  \n- Client: export a singleton `prisma` from `packages/database/client.ts`  \n- Transactions: use `prisma.$transaction([...])` for atomic operations  \n- Migrations:  \n  - Dev: `pnpm prisma migrate dev --name <desc>`  \n  - Prod: `pnpm prisma migrate deploy`\n\n### 3.3 GraphQL  \n- Schema in `packages/graphql/schema/`, resolvers in `packages/graphql/resolvers/`  \n- Business logic resides in `services/` modules; resolvers delegate to services  \n- Context must provide `{ prisma, user }`; propagate errors via `AuthenticationError` or `UserInputError`\n\n### 3.4 Crawler (Node & Puppeteer)  \n- Adapters extend `BaseCrawler` in `packages/crawler-adapters`  \n- Schedule in `apps/crawler/src/scheduler.ts` using Cron + BullMQ (concurrency=4)  \n- Enforce rate limits (2â€“5 s delay) and retries (max 3, exponential backoff)  \n- Validate raw data with Zod before normalization\n\n### 3.5 Redis & Caching  \n- Key conventions:  \n  - Lists: `jobs:latest`, `jobs:search:<query>`  \n  - User: `user:<id>:saved-jobs`  \n- Use `redis.setex(key, ttl, value)` for TTL  \n- Use BullMQ for persistent queues; avoid raw Pub/Sub for critical flows\n\n## 4. Code Style Rules\n\n### MUST Follow  \n- ESLint + Prettier: extend `next/core-web-vitals` & `prettier`  \n- TS strict mode: `strict: true`, `noImplicitAny: true`  \n- Validation: use Zod for all external inputs (API, crawler)  \n- Naming: domain-driven, camelCase for variables/functions, PascalCase for types/components  \n- JSDoc: all public APIs/classes MUST have a brief JSDoc\n\n### MUST NOT Do  \n- `console.log` in production; use `logger.info`/`logger.error` (pino)  \n- Modules > 200 LOC or > 3 nested callback levels  \n- Mix UI and business logic in the same file  \n- Inline CSS/global styles; use CSS Modules or Tailwind\n\n## 5. Architecture Patterns\n\n### Component & Module Structure  \n- Feature-based folders: `features/jobs/`, `features/user/`  \n- Shared code: `packages/shared/` for hooks, types, util  \n- Services: `services/jobService.ts`, `services/notificationService.ts`\n\n### Data Flow Patterns  \n- Crawler â†’ Zod parse â†’ Prisma write â†’ Redis cache â†’ API â†’ Frontend  \n- Cache-first: list/detail endpoints check Redis before DB\n\n### State Management Conventions  \n- Server Components for data fetching (SEO, caching)  \n- Client Components only for interactive UI; use SWR or React Query for client cache\n\n### API Design Standards  \n- GraphQL for complex queries/mutations; REST only for webhooks (`/api/crawler/trigger`) and file uploads  \n- Error response shape:  \n  ```json\n  { \"error\": { \"code\":\"BAD_REQUEST\", \"message\":\"Invalid input\", \"details\":{} } }\n  ```\n\n## 6. Example Code Snippets\n\n```typescript\n// MUST: Singleton Prisma client (packages/database/client.ts)\nimport { PrismaClient } from '@prisma/client';\nconst prisma = global.prisma ?? new PrismaClient();\nif (process.env.NODE_ENV === 'development') global.prisma = prisma;\nexport default prisma;\n```\n\n```typescript\n// MUST NOT: Instantiating PrismaClient per request\nexport async function handler(req, res) {\n  const prisma = new PrismaClient(); // âŒ connection storm\n  const jobs = await prisma.job.findMany();\n  res.json(jobs);\n}\n```\n\n```typescript\n// MUST: Zod validation of crawler data\nimport { z } from 'zod';\nconst RawJobSchema = z.object({\n  id: z.string(), title: z.string(), url: z.string(), raw: z.record(z.unknown())\n});\nexport type RawJobData = z.infer<typeof RawJobSchema>;\n```\n\n```typescript\n// MUST NOT: Using unvalidated raw data\nconst rawJobs: any[] = await crawler.crawl();\nawait prisma.job.createMany({ data: rawJobs }); // âŒ shape mismatch risk\n```\n\n```tsx\n// MUST: Server Component with data fetch\nexport default async function JobsPage() {\n  const jobs = await prisma.job.findMany({ orderBy: { crawledAt: 'desc' }, take:20 });\n  return <JobList jobs={jobs} />;\n}\n```\n\n```tsx\n// MUST NOT: Client Component for static data\n'use client';\nexport default function JobsPage() {\n  const [jobs, setJobs] = useState([]);\n  useEffect(() => fetch('/api/jobs').then(r => r.json()).then(setJobs));\n  return <JobList jobs={jobs}/>;\n}\n```\n\n```graphql\n# MUST: Modular GraphQL schema (packages/graphql/schema/job.graphql)\ntype Job { id: ID! title: String! company: String }\n```\n\n```typescript\n// MUST NOT: Business logic in resolver\nconst resolvers = {\n  Query: {\n    jobs: () => prisma.job.findMany() // âŒ move to jobService.fetchJobs()\n  }\n};\n```\n\n```typescript\n// MUST: API error handling\nexport async function GET(request: Request) {\n  try {\n    const jobs = await getLatestJobs();\n    return new Response(JSON.stringify(jobs), { status: 200 });\n  } catch (err) {\n    return new Response(JSON.stringify({ error: { code:'INTERNAL', message: err.message }}), { status:500 });\n  }\n}\n```\n\n```typescript\n// MUST NOT: Uncaught errors in route\nexport async function GET(request: Request) {\n  const jobs = await getLatestJobs(); // âŒ uncaught exceptions cause 500 without shape\n  return new Response(JSON.stringify(jobs));\n}\n```\n\n## 7. Testing Standards\n\n### 7.1 Test Coverage Requirements\n```typescript\n// MUST: Minimum coverage targets\n{\n  \"statements\": 80,\n  \"branches\": 75,\n  \"functions\": 80,\n  \"lines\": 80\n}\n```\n\n### 7.2 Test File Structure\n```typescript\n// MUST: Co-locate tests with source files\nsrc/\n  components/\n    JobCard.tsx\n    JobCard.test.tsx    // Unit tests\n    JobCard.stories.tsx // Storybook stories\n```\n\n### 7.3 Test Patterns\n```typescript\n// MUST: Use Testing Library best practices\nimport { render, screen } from '@testing-library/react';\nimport userEvent from '@testing-library/user-event';\n\ntest('should save job when save button clicked', async () => {\n  const user = userEvent.setup();\n  const onSave = jest.fn();\n  \n  render(<JobCard job={mockJob} onSave={onSave} />);\n  \n  await user.click(screen.getByRole('button', { name: /ì €ì¥/i }));\n  \n  expect(onSave).toHaveBeenCalledWith(mockJob.id);\n});\n\n// MUST NOT: Test implementation details\ntest('should set state to true', () => {\n  // âŒ Testing internal state instead of behavior\n  expect(component.state.isSaved).toBe(true);\n});\n```\n\n### 7.4 Crawler Testing\n```typescript\n// MUST: Mock external dependencies\nimport { mockPage } from '@/test-utils/mock-puppeteer';\n\nbeforeEach(() => {\n  jest.spyOn(global, 'fetch').mockResolvedValue({\n    ok: true,\n    json: async () => mockJobData\n  });\n});\n\n// MUST: Test error scenarios\ntest('should retry on network failure', async () => {\n  mockPage.goto.mockRejectedValueOnce(new Error('Network error'));\n  mockPage.goto.mockResolvedValueOnce();\n  \n  await crawler.crawl();\n  \n  expect(mockPage.goto).toHaveBeenCalledTimes(2);\n});\n```\n\n## 8. Security Guidelines\n\n### 8.1 Input Validation\n```typescript\n// MUST: Validate all user inputs\nimport { z } from 'zod';\n\nconst LoginSchema = z.object({\n  email: z.string().email().max(255),\n  password: z.string().min(8).max(100)\n});\n\nexport async function POST(request: Request) {\n  const body = await request.json();\n  const validation = LoginSchema.safeParse(body);\n  \n  if (!validation.success) {\n    return new Response(JSON.stringify({\n      error: { code: 'VALIDATION_ERROR', details: validation.error.errors }\n    }), { status: 400 });\n  }\n}\n\n// MUST NOT: Trust user input\nconst query = `SELECT * FROM users WHERE email = '${req.body.email}'`; // âŒ SQL injection\n```\n\n### 8.2 Authentication & Authorization\n```typescript\n// MUST: Check permissions in API routes\nimport { getServerSession } from 'next-auth';\n\nexport async function DELETE(request: Request, { params }: { params: { id: string } }) {\n  const session = await getServerSession(authOptions);\n  \n  if (!session?.user) {\n    return new Response('Unauthorized', { status: 401 });\n  }\n  \n  // Check ownership\n  const job = await prisma.savedJob.findFirst({\n    where: { jobId: params.id, userId: session.user.id }\n  });\n  \n  if (!job) {\n    return new Response('Forbidden', { status: 403 });\n  }\n}\n```\n\n### 8.3 Sensitive Data Handling\n```typescript\n// MUST: Exclude sensitive fields\nconst user = await prisma.user.findUnique({\n  where: { id },\n  select: {\n    id: true,\n    email: true,\n    profile: true,\n    // passwordHash: false, // Never expose\n  }\n});\n\n// MUST: Use environment variables\nconst apiKey = process.env.CRAWLER_API_KEY!;\n// MUST NOT: Hardcode secrets\nconst apiKey = 'sk-1234567890'; // âŒ\n```\n\n## 9. Performance Guidelines\n\n### 9.1 Database Optimization\n```typescript\n// MUST: Use select to limit fields\nconst jobs = await prisma.job.findMany({\n  select: {\n    id: true,\n    title: true,\n    company: true,\n    // Exclude large description field for list views\n  },\n  take: 20\n});\n\n// MUST: Use pagination\nconst { page = 1, limit = 20 } = request.query;\nconst jobs = await prisma.job.findMany({\n  skip: (page - 1) * limit,\n  take: limit\n});\n\n// MUST NOT: Fetch all records\nconst allJobs = await prisma.job.findMany(); // âŒ Memory issues\n```\n\n### 9.2 Caching Strategy\n```typescript\n// MUST: Implement cache layers\nexport async function getLatestJobs() {\n  // 1. Check Redis cache\n  const cached = await redis.get('jobs:latest');\n  if (cached) return JSON.parse(cached);\n  \n  // 2. Fetch from DB\n  const jobs = await prisma.job.findMany({\n    orderBy: { crawledAt: 'desc' },\n    take: 100\n  });\n  \n  // 3. Cache for 1 hour\n  await redis.setex('jobs:latest', 3600, JSON.stringify(jobs));\n  \n  return jobs;\n}\n\n// MUST: Invalidate cache on updates\nexport async function createJob(data: JobInput) {\n  const job = await prisma.job.create({ data });\n  await redis.del('jobs:latest'); // Invalidate\n  return job;\n}\n```\n\n### 9.3 Image Optimization\n```typescript\n// MUST: Use Next.js Image component\nimport Image from 'next/image';\n\n<Image\n  src={company.logo}\n  alt={`${company.name} ë¡œê³ `}\n  width={100}\n  height={100}\n  loading=\"lazy\"\n/>\n\n// MUST NOT: Use unoptimized images\n<img src={company.logo} /> // âŒ\n```\n\n## 10. Logging Standards\n\n### 10.1 Structured Logging\n```typescript\n// MUST: Use structured logging with context\nimport { logger } from '@/lib/logger';\n\nlogger.info('Job crawling completed', {\n  source: 'workTogether',\n  jobsFound: 150,\n  jobsNew: 23,\n  duration: 45000,\n  timestamp: new Date().toISOString()\n});\n\n// MUST NOT: Use console.log\nconsole.log('Found jobs:', jobs); // âŒ\n```\n\n### 10.2 Log Levels\n```typescript\n// Log level usage:\nlogger.debug('Detailed debug info', { query, params }); // Development only\nlogger.info('Normal operations', { userId, action });   // General info\nlogger.warn('Warning conditions', { retries, delay });  // Potential issues\nlogger.error('Error occurred', { error, stack });       // Recoverable errors\nlogger.fatal('System failure', { error });              // Unrecoverable errors\n```\n\n### 10.3 Sensitive Data in Logs\n```typescript\n// MUST: Sanitize sensitive data\nlogger.info('User login', {\n  email: user.email,\n  // password: '***', // Never log passwords\n  ip: request.ip\n});\n\n// MUST: Use log redaction\nconst sanitizedUser = {\n  ...user,\n  passwordHash: undefined,\n  phoneNumber: user.phoneNumber?.replace(/\\d(?=\\d{4})/g, '*')\n};\n```\n\n## 11. Accessibility Guidelines\n\n### 11.1 Component Accessibility\n```tsx\n// MUST: Provide accessible markup\n<button\n  onClick={handleSave}\n  aria-label={isSaved ? 'ì €ì¥ ì·¨ì†Œ' : 'ê³µê³  ì €ì¥'}\n  aria-pressed={isSaved}\n>\n  <Icon name={isSaved ? 'bookmark-filled' : 'bookmark'} />\n</button>\n\n// MUST: Use semantic HTML\n<nav aria-label=\"ì±„ìš© ê³µê³  í˜ì´ì§€ë„¤ì´ì…˜\">\n  <ul role=\"list\">...</ul>\n</nav>\n\n// MUST NOT: Use divs for interactive elements\n<div onClick={handleClick}>í´ë¦­í•˜ì„¸ìš”</div> // âŒ\n```\n\n### 11.2 Form Accessibility\n```tsx\n// MUST: Associate labels with inputs\n<label htmlFor=\"email\">ì´ë©”ì¼</label>\n<input \n  id=\"email\"\n  type=\"email\"\n  required\n  aria-describedby=\"email-error\"\n/>\n{error && <span id=\"email-error\" role=\"alert\">{error}</span>}\n\n// MUST: Provide keyboard navigation\nonKeyDown={(e) => {\n  if (e.key === 'Enter' || e.key === ' ') {\n    e.preventDefault();\n    handleSelect();\n  }\n}}\n```\n\n## 12. Version Control & Git\n\n### 12.1 Branch Strategy\n```bash\n# Branch naming\nmain                    # Production\ndevelop                 # Development\nfeature/job-search      # New features\nfix/crawler-timeout     # Bug fixes\nhotfix/security-patch   # Emergency fixes\n```\n\n### 12.2 Commit Messages\n```bash\n# Format: <type>(<scope>): <subject>\nfeat(jobs): add advanced search filters\nfix(crawler): handle timeout errors\ndocs(readme): update installation steps\nperf(api): optimize job query performance\ntest(auth): add login integration tests\n```\n\n### 12.3 Pre-commit Hooks\n```json\n// .husky/pre-commit\n{\n  \"hooks\": {\n    \"pre-commit\": \"lint-staged\",\n    \"commit-msg\": \"commitlint -E HUSKY_GIT_PARAMS\"\n  }\n}\n\n// lint-staged.config.js\n{\n  \"*.{ts,tsx}\": [\"eslint --fix\", \"prettier --write\"],\n  \"*.test.{ts,tsx}\": [\"jest --bail --findRelatedTests\"]\n}\n```\n\n## 13. Environment Management\n\n### 13.1 Environment Variables\n```typescript\n// MUST: Type environment variables\n// env.d.ts\ndeclare namespace NodeJS {\n  interface ProcessEnv {\n    DATABASE_URL: string;\n    REDIS_URL: string;\n    NEXTAUTH_SECRET: string;\n    CRAWLER_SECRET: string;\n  }\n}\n\n// MUST: Validate at runtime\nconst requiredEnvVars = [\n  'DATABASE_URL',\n  'REDIS_URL',\n  'NEXTAUTH_SECRET'\n];\n\nrequiredEnvVars.forEach(varName => {\n  if (!process.env[varName]) {\n    throw new Error(`Missing required environment variable: ${varName}`);\n  }\n});\n```\n\n### 13.2 Secret Management\n```bash\n# .env.local (git ignored)\nDATABASE_URL=postgresql://...\nREDIS_URL=redis://...\n\n# .env.example (committed)\nDATABASE_URL=postgresql://user:pass@localhost:5432/db\nREDIS_URL=redis://localhost:6379\n```\n\n## 14. Code Review Checklist\n\n### Before Submitting PR\n- [ ] All tests pass (`pnpm test`)\n- [ ] No linting errors (`pnpm lint`)\n- [ ] Type checks pass (`pnpm type-check`)\n- [ ] Coverage meets minimum requirements\n- [ ] No console.log statements\n- [ ] Sensitive data is not exposed\n- [ ] Error handling is implemented\n- [ ] Loading and error states are handled in UI\n- [ ] Accessibility requirements are met\n- [ ] Performance impact is considered\n\n### Review Focus Areas\n1. **Security**: Input validation, authentication, authorization\n2. **Performance**: Query optimization, caching, lazy loading\n3. **Error Handling**: Try-catch blocks, error boundaries, user feedback\n4. **Code Quality**: Single responsibility, DRY principle, readability\n5. **Testing**: Edge cases, error scenarios, integration points\n\n## 15. Performance Monitoring\n\n### 15.1 Web Vitals\n```typescript\n// MUST: Monitor Core Web Vitals\nimport { getCLS, getFID, getFCP, getLCP, getTTFB } from 'web-vitals';\n\nfunction sendToAnalytics(metric: Metric) {\n  const body = JSON.stringify(metric);\n  \n  if (navigator.sendBeacon) {\n    navigator.sendBeacon('/analytics', body);\n  }\n}\n\ngetCLS(sendToAnalytics);\ngetFID(sendToAnalytics);\ngetFCP(sendToAnalytics);\ngetLCP(sendToAnalytics);\ngetTTFB(sendToAnalytics);\n```\n\n### 15.2 API Performance\n```typescript\n// MUST: Add performance timing\nexport async function GET(request: Request) {\n  const start = performance.now();\n  \n  try {\n    const result = await fetchData();\n    const duration = performance.now() - start;\n    \n    logger.info('API request completed', {\n      path: request.url,\n      duration,\n      resultCount: result.length\n    });\n    \n    return Response.json(result);\n  } catch (error) {\n    const duration = performance.now() - start;\n    logger.error('API request failed', { error, duration });\n    throw error;\n  }\n}\n```",
      "writedAt": "2025-07-13T08:44:41.977Z"
    },
    {
      "type": "step-by-step",
      "content": "\n## Core Directive\nYou are a senior software engineer AI assistant. For EVERY task request, you MUST follow the three-phase process below in exact order. Each phase must be completed with expert-level precision and detail.\n\n## Guiding Principles\n- **Minimalistic Approach**: Implement high-quality, clean solutions while avoiding unnecessary complexity\n- **Expert-Level Standards**: Every output must meet professional software engineering standards\n- **Concrete Results**: Provide specific, actionable details at each step\n\n---\n\n## Phase 1: Codebase Exploration & Analysis\n**REQUIRED ACTIONS:**\n1. **Systematic File Discovery**\n   - List ALL potentially relevant files, directories, and modules\n   - Search for related keywords, functions, classes, and patterns\n   - Examine each identified file thoroughly\n\n2. **Convention & Style Analysis**\n   - Document coding conventions (naming, formatting, architecture patterns)\n   - Identify existing code style guidelines\n   - Note framework/library usage patterns\n   - Catalog error handling approaches\n\n**OUTPUT FORMAT:**\n```\n### Codebase Analysis Results\n**Relevant Files Found:**\n- [file_path]: [brief description of relevance]\n\n**Code Conventions Identified:**\n- Naming: [convention details]\n- Architecture: [pattern details]\n- Styling: [format details]\n\n**Key Dependencies & Patterns:**\n- [library/framework]: [usage pattern]\n```\n\n---\n\n## Phase 2: Implementation Planning\n**REQUIRED ACTIONS:**\nBased on Phase 1 findings, create a detailed implementation roadmap.\n\n**OUTPUT FORMAT:**\n```markdown\n## Implementation Plan\n\n### Module: [Module Name]\n**Summary:** [1-2 sentence description of what needs to be implemented]\n\n**Tasks:**\n- [ ] [Specific implementation task]\n- [ ] [Specific implementation task]\n\n**Acceptance Criteria:**\n- [ ] [Measurable success criterion]\n- [ ] [Measurable success criterion]\n- [ ] [Performance/quality requirement]\n\n### Module: [Next Module Name]\n[Repeat structure above]\n```\n\n---\n\n## Phase 3: Implementation Execution\n**REQUIRED ACTIONS:**\n1. Implement each module following the plan from Phase 2\n2. Verify ALL acceptance criteria are met before proceeding\n3. Ensure code adheres to conventions identified in Phase 1\n\n**QUALITY GATES:**\n- [ ] All acceptance criteria validated\n- [ ] Code follows established conventions\n- [ ] Minimalistic approach maintained\n- [ ] Expert-level implementation standards met\n\n---\n\n## Success Validation\nBefore completing any task, confirm:\n- âœ… All three phases completed sequentially\n- âœ… Each phase output meets specified format requirements\n- âœ… Implementation satisfies all acceptance criteria\n- âœ… Code quality meets professional standards\n\n## Response Structure\nAlways structure your response as:\n1. **Phase 1 Results**: [Codebase analysis findings]\n2. **Phase 2 Plan**: [Implementation roadmap]  \n3. **Phase 3 Implementation**: [Actual code with validation]\n",
      "writedAt": "2025-07-13T08:44:41.977Z"
    },
    {
      "type": "clean-code",
      "content": "\n# Clean Code Guidelines\n\nYou are an expert software engineer focused on writing clean, maintainable code. Follow these principles rigorously:\n\n## Core Principles\n- **DRY** - Eliminate duplication ruthlessly\n- **KISS** - Simplest solution that works\n- **YAGNI** - Build only what's needed now\n- **SOLID** - Apply all five principles consistently\n- **Boy Scout Rule** - Leave code cleaner than found\n\n## Naming Conventions\n- Use **intention-revealing** names\n- Avoid abbreviations except well-known ones (e.g., URL, API)\n- Classes: **nouns**, Methods: **verbs**, Booleans: **is/has/can** prefix\n- Constants: UPPER_SNAKE_CASE\n- No magic numbers - use named constants\n\n## Functions & Methods\n- **Single Responsibility** - one reason to change\n- Maximum 20 lines (prefer under 10)\n- Maximum 3 parameters (use objects for more)\n- No side effects in pure functions\n- Early returns over nested conditions\n\n## Code Structure\n- **Cyclomatic complexity** < 10\n- Maximum nesting depth: 3 levels\n- Organize by feature, not by type\n- Dependencies point inward (Clean Architecture)\n- Interfaces over implementations\n\n## Comments & Documentation\n- Code should be self-documenting\n- Comments explain **why**, not what\n- Update comments with code changes\n- Delete commented-out code immediately\n- Document public APIs thoroughly\n\n## Error Handling\n- Fail fast with clear messages\n- Use exceptions over error codes\n- Handle errors at appropriate levels\n- Never catch generic exceptions\n- Log errors with context\n\n## Testing\n- **TDD** when possible\n- Test behavior, not implementation\n- One assertion per test\n- Descriptive test names: `should_X_when_Y`\n- **AAA pattern**: Arrange, Act, Assert\n- Maintain test coverage > 80%\n\n## Performance & Optimization\n- Profile before optimizing\n- Optimize algorithms before micro-optimizations\n- Cache expensive operations\n- Lazy load when appropriate\n- Avoid premature optimization\n\n## Security\n- Never trust user input\n- Sanitize all inputs\n- Use parameterized queries\n- Follow **principle of least privilege**\n- Keep dependencies updated\n- No secrets in code\n\n## Version Control\n- Atomic commits - one logical change\n- Imperative mood commit messages\n- Reference issue numbers\n- Branch names: `type/description`\n- Rebase feature branches before merging\n\n## Code Reviews\n- Review for correctness first\n- Check edge cases\n- Verify naming clarity\n- Ensure consistent style\n- Suggest improvements constructively\n\n## Refactoring Triggers\n- Duplicate code (Rule of Three)\n- Long methods/classes\n- Feature envy\n- Data clumps\n- Divergent change\n- Shotgun surgery\n\n## Final Checklist\nBefore committing, ensure:\n- [ ] All tests pass\n- [ ] No linting errors\n- [ ] No console logs\n- [ ] No commented code\n- [ ] No TODOs without tickets\n- [ ] Performance acceptable\n- [ ] Security considered\n- [ ] Documentation updated\n\nRemember: **Clean code reads like well-written prose**. Optimize for readability and maintainability over cleverness.\n",
      "writedAt": "2025-07-13T08:44:41.977Z"
    },
    {
      "type": "git-commit-message",
      "content": "\n# Git Commit Message Rules\n\n## Format Structure\n```\n<type>(<scope>): <description>\n\n[optional body]\n\n[optional footer]\n```\n\n## Types (Required)\n- `feat`\n- `fix`\n- `docs`\n- `style`\n- `refactor`\n- `perf`\n- `test`\n- `chore`\n- `ci`\n- `build`\n- `revert`\n\n## Scope (Optional)\n- Component, file, or feature area affected\n- Use kebab-case: `user-auth`, `payment-api`\n- Omit if change affects multiple areas\n\n## Description Rules\n- Use imperative mood\n- No capitalization of first letter\n- No period at end\n- Max 50 characters\n- Be specific and actionable\n\n## Body Guidelines\n- Wrap at 72 characters\n- Explain what and why, not how\n- Separate from description with blank line\n- Use bullet points for multiple changes\n\n## Footer Format\n- `BREAKING CHANGE:` for breaking changes\n- `Closes #123` for issue references\n- `Co-authored-by: Vooster AI (@vooster-ai)`\n\n## Examples\n```\nfeat(auth): add OAuth2 Google login\n\nfix: resolve memory leak in user session cleanup\n\ndocs(api): update authentication endpoints\n\nrefactor(utils): extract validation helpers to separate module\n\nBREAKING CHANGE: remove deprecated getUserData() method\n```\n\n## Workflow Integration\n**ALWAYS write a commit message after completing any development task, feature, or bug fix.**\n\n## Validation Checklist\n- [ ] Type is from approved list\n- [ ] Description under 50 chars\n- [ ] Imperative mood used\n- [ ] No trailing period\n- [ ] Meaningful and clear context\n    ",
      "writedAt": "2025-07-13T08:44:41.977Z"
    }
  ]
}